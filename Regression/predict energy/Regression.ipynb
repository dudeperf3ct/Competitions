{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "ct2PZBMrcN6V"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from timeit import timeit\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge, HuberRegressor, TheilSenRegressor, RANSACRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "import xgboost as xg\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 942,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 721,
     "status": "error",
     "timestamp": 1518699303957,
     "user": {
      "displayName": "Shubham Gandhi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "101251038284028034757"
     },
     "user_tz": -330
    },
    "id": "vSjI44pgcN67",
    "outputId": "efd4837d-8b27-419a-bec0-383babab5af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (15780, 26))\n",
      "   Observation         T1    RH_1    T2       RH_2         T3       RH_3  \\\n",
      "0         1111  22.700000  37.200  21.0  38.000000  23.390000  37.290000   \n",
      "1         1112  21.500000  41.045  20.5  39.133333  22.926667  39.526667   \n",
      "2         1113  21.666667  38.000  22.6  35.700000  21.890000  36.590000   \n",
      "\n",
      "          T4       RH_4         T5   ...         RH_8     T9       RH_9  \\\n",
      "0  22.832857  34.942857  20.500000   ...    45.360000  20.20  38.663333   \n",
      "1  21.700000  34.126667  18.633333   ...    34.663333  19.73  37.933333   \n",
      "2  22.000000  35.530000  19.000000   ...    38.545000  19.79  39.430000   \n",
      "\n",
      "   T_out  Press_mm_hg     RH_out  Windspeed  Visibility  Tdewpoint  Energy  \n",
      "0  12.80   760.050000  62.000000        3.5        28.0       5.65      70  \n",
      "1   8.47   764.166667  48.166667        8.0        26.5      -1.92     210  \n",
      "2  10.60   757.600000  57.000000        2.0        27.0       2.40      50  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Index([u'Observation', u'T1', u'RH_1', u'T2', u'RH_2', u'T3', u'RH_3', u'T4',\n",
      "       u'RH_4', u'T5', u'RH_5', u'T6', u'RH_6', u'T7', u'RH_7', u'T8', u'RH_8',\n",
      "       u'T9', u'RH_9', u'T_out', u'Press_mm_hg', u'RH_out', u'Windspeed',\n",
      "       u'Visibility', u'Tdewpoint', u'Energy'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "print ('Training set', data.shape)\n",
    "print (data.head(3))\n",
    "print (data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "FBP4wyYDcN7Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Testing set', (3945, 25))\n",
      "   Observation    T1   RH_1     T2       RH_2         T3       RH_3     T4  \\\n",
      "0        50001  21.1  39.90  19.29  41.260000  21.500000  40.700000  18.89   \n",
      "1        50002  22.6  39.03  20.79  40.463333  22.290000  38.290000  20.29   \n",
      "2        50003  21.0  35.59  19.79  34.900000  21.166667  35.833333  20.39   \n",
      "\n",
      "    RH_4         T5    ...         T8       RH_8     T9   RH_9  T_out  \\\n",
      "0  41.20  18.088889    ...      21.60  47.090000  18.10  44.90   2.70   \n",
      "1  36.70  20.760000    ...      23.76  39.266667  19.39  37.50   7.27   \n",
      "2  33.09  18.000000    ...      22.60  34.126667  18.20  39.79   6.05   \n",
      "\n",
      "   Press_mm_hg     RH_out  Windspeed  Visibility  Tdewpoint  \n",
      "0   733.633333  98.166667        2.0   34.833333       2.43  \n",
      "1   756.666667  82.000000        2.0   40.000000       4.40  \n",
      "2   751.250000  50.000000        6.5   34.500000      -3.70  \n",
      "\n",
      "[3 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "print ('Testing set', test_data.shape)\n",
    "print (test_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "pRABETkAcN7l",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Energy          True\n",
      "Observation    False\n",
      "Press_mm_hg    False\n",
      "RH_1           False\n",
      "RH_2           False\n",
      "RH_3           False\n",
      "RH_4           False\n",
      "RH_5           False\n",
      "RH_6           False\n",
      "RH_7           False\n",
      "RH_8           False\n",
      "RH_9           False\n",
      "RH_out         False\n",
      "T1             False\n",
      "T2             False\n",
      "T3             False\n",
      "T4             False\n",
      "T5             False\n",
      "T6             False\n",
      "T7             False\n",
      "T8             False\n",
      "T9             False\n",
      "T_out          False\n",
      "Tdewpoint      False\n",
      "Visibility     False\n",
      "Windspeed      False\n",
      "dtype: bool, Energy         3945\n",
      "Observation       0\n",
      "Press_mm_hg       0\n",
      "RH_1              0\n",
      "RH_2              0\n",
      "RH_3              0\n",
      "RH_4              0\n",
      "RH_5              0\n",
      "RH_6              0\n",
      "RH_7              0\n",
      "RH_8              0\n",
      "RH_9              0\n",
      "RH_out            0\n",
      "T1                0\n",
      "T2                0\n",
      "T3                0\n",
      "T4                0\n",
      "T5                0\n",
      "T6                0\n",
      "T7                0\n",
      "T8                0\n",
      "T9                0\n",
      "T_out             0\n",
      "Tdewpoint         0\n",
      "Visibility        0\n",
      "Windspeed         0\n",
      "dtype: int64)\n",
      "             Energy   Observation   Press_mm_hg          RH_1          RH_2  \\\n",
      "count  15780.000000  19725.000000  19725.000000  19725.000000  19725.000000   \n",
      "mean      97.294043  17595.000000    755.520587     40.260559     40.422081   \n",
      "std      100.932234  17673.072717      7.399354      3.979459      4.069757   \n",
      "min       10.000000   1111.000000    729.300000     27.023333     20.463333   \n",
      "25%       50.000000   6042.000000    750.933333     37.333333     37.900000   \n",
      "50%       60.000000  10973.000000    756.100000     39.656667     40.500000   \n",
      "75%      100.000000  15904.000000    760.933333     43.066667     43.260000   \n",
      "max      850.000000  53945.000000    772.300000     63.360000     56.026667   \n",
      "\n",
      "               RH_3          RH_4          RH_5          RH_6          RH_7  \\\n",
      "count  19725.000000  19725.000000  19725.000000  19725.000000  19725.000000   \n",
      "mean      39.243014     39.027640     50.952021     54.606832     35.389465   \n",
      "std        3.254868      4.341706      9.022723     31.147868      5.114485   \n",
      "min       28.766667     27.660000     29.815000      1.000000     23.200000   \n",
      "25%       36.900000     35.530000     45.400000     30.026667     31.500000   \n",
      "50%       38.530000     38.400000     49.090000     55.290000     34.863333   \n",
      "75%       41.760000     42.163333     53.672222     83.200000     39.000000   \n",
      "max       50.163333     51.090000     96.321667     99.900000     51.400000   \n",
      "\n",
      "           ...                 T4            T5            T6            T7  \\\n",
      "count      ...       19725.000000  19725.000000  19725.000000  19725.000000   \n",
      "mean       ...          20.855979     19.592584      7.912075     20.267593   \n",
      "std        ...           2.042741      1.844670      6.089966      2.109913   \n",
      "min        ...          15.100000     15.330000     -6.065000     15.390000   \n",
      "25%        ...          19.533333     18.280000      3.626667     18.700000   \n",
      "50%        ...          20.666667     19.390000      7.300000     20.033333   \n",
      "75%        ...          22.100000     20.625000     11.256000     21.600000   \n",
      "max        ...          26.200000     25.795000     28.290000     26.000000   \n",
      "\n",
      "                 T8            T9         T_out     Tdewpoint    Visibility  \\\n",
      "count  19725.000000  19725.000000  19725.000000  19725.000000  19725.000000   \n",
      "mean      22.029491     19.486469      7.413777      3.762306     38.325847   \n",
      "std        1.956083      2.014568      5.318206      4.195234     11.793070   \n",
      "min       16.306667     14.890000     -5.000000     -6.600000      1.000000   \n",
      "25%       20.790000     18.000000      3.670000      0.900000     29.000000   \n",
      "50%       22.100000     19.390000      6.920000      3.430000     40.000000   \n",
      "75%       23.390000     20.600000     10.400000      6.570000     40.000000   \n",
      "max       27.230000     24.500000     26.100000     15.500000     66.000000   \n",
      "\n",
      "          Windspeed  \n",
      "count  19725.000000  \n",
      "mean       4.039949  \n",
      "std        2.451202  \n",
      "min        0.000000  \n",
      "25%        2.000000  \n",
      "50%        3.666667  \n",
      "75%        5.500000  \n",
      "max       14.000000  \n",
      "\n",
      "[8 rows x 26 columns]\n",
      "Energy         float64\n",
      "Observation      int64\n",
      "Press_mm_hg    float64\n",
      "RH_1           float64\n",
      "RH_2           float64\n",
      "RH_3           float64\n",
      "RH_4           float64\n",
      "RH_5           float64\n",
      "RH_6           float64\n",
      "RH_7           float64\n",
      "RH_8           float64\n",
      "RH_9           float64\n",
      "RH_out         float64\n",
      "T1             float64\n",
      "T2             float64\n",
      "T3             float64\n",
      "T4             float64\n",
      "T5             float64\n",
      "T6             float64\n",
      "T7             float64\n",
      "T8             float64\n",
      "T9             float64\n",
      "T_out          float64\n",
      "Tdewpoint      float64\n",
      "Visibility     float64\n",
      "Windspeed      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.concat([data, test_data])\n",
    "print (all_data.isnull().any(), all_data.isnull().sum())\n",
    "print (all_data.describe())\n",
    "print (all_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "rVjvI2npcN72",
    "outputId": "c8cef955-41ed-46e8-976e-6b113f0bb217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total dataset', (19725, 25))\n",
      "('Train labels:', (19725,))\n"
     ]
    }
   ],
   "source": [
    "drop_features = ['Energy']\n",
    "big_data = all_data.drop(drop_features, axis=1)\n",
    "\n",
    "train_labels = all_data['Energy']\n",
    "print ('Total dataset', big_data.shape) \n",
    "print ('Train labels:', train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "wSgt0-p_cN8H",
    "outputId": "0d85c540-29ce-4c75-d37f-379821bd5715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Observation  Press_mm_hg      RH_1      RH_2      RH_3      RH_4      RH_5  \\\n",
      "0         1111     0.612152 -0.769109 -0.595156 -0.600044 -0.940848 -0.900566   \n",
      "1         1112     1.168521  0.197128 -0.316672  0.087149 -1.128841 -0.697001   \n",
      "2         1113     0.281033 -0.568071 -1.160315 -0.815112 -0.805611 -0.526686   \n",
      "\n",
      "       RH_6      RH_7      RH_8    ...            T4        T5        T6  \\\n",
      "0 -1.443907  0.071277  0.463657    ...      0.967782  0.491925  0.758851   \n",
      "1 -1.370278 -2.005361 -1.583628    ...      0.413191 -0.520025  0.374055   \n",
      "2 -1.061849 -0.337507 -0.840698    ...      0.560056 -0.321249  0.401971   \n",
      "\n",
      "         T7        T8        T9     T_out  Tdewpoint  Visibility  Windspeed  \n",
      "0  0.849539  0.342790  0.354194  1.012815   0.449973   -0.875608  -0.220285  \n",
      "1  0.247603  0.458671  0.120888  0.198610  -1.354501   -1.002805   1.615596  \n",
      "2 -0.316416 -0.071313  0.150672  0.599131  -0.324735   -0.960406  -0.832245  \n",
      "\n",
      "[3 rows x 25 columns]\n",
      "('Training shape:', (15780, 25), (15780,), 'Testing shape:', (3945, 25))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "sc = StandardScaler()\n",
    "for i, c in enumerate(big_data.columns):\n",
    "    if big_data.dtypes[i] == 'object':\n",
    "        big_data[c] = le.fit_transform(big_data[c])\n",
    "    elif big_data.dtypes[i] in ['int', 'float'] and c!='Observation':\n",
    "        big_data[c] = sc.fit_transform(big_data[c])\n",
    "\n",
    "print (big_data.head(3))\n",
    "\n",
    "train_data = big_data[:len(data)]\n",
    "train_labels = train_labels[:len(data)]\n",
    "test_x = big_data[len(data):]\n",
    "\n",
    "print ('Training shape:', train_data.shape, train_labels.shape, 'Testing shape:', test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "aLB2SMNrcN8Z",
    "outputId": "64e4663d-ac38-440c-a453-02e648d553a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training shape:', (11835, 25), (11835,))\n",
      "('validation shape:', (3945, 25), (3945,))\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_data, train_labels, test_size=0.25)\n",
    "print ('training shape:', train_x.shape, train_y.shape)\n",
    "print ('validation shape:', val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "3WE4S0ascN8v"
   },
   "outputs": [],
   "source": [
    "def cv_model(clf):     \n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=45)\n",
    "    scores = cross_val_score(clf, train_x, train_y, cv=cv, scoring='r2')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "9Xv4FKgLcN9F"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training score:', 0.46688108657756544)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation score:', 0.50246146999076768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "clf = RandomForestRegressor(n_estimators=300, verbose=1)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "RASzMFrIcN9X",
    "outputId": "c9c951df-3b24-42d8-e393-fc33de555b43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   43.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   41.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   42.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   45.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   38.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training score:', 0.50469971750527698)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   48.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation score:', 0.58018719970351174)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "clf = ExtraTreesRegressor(n_estimators=500, verbose=1)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "hG2DJnv0cN9r",
    "outputId": "369b41a6-212e-4572-ca6c-45acdf220217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training score:', 0.13695990185421228)\n",
      "('Validation score:', 0.14583264321656797)\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "IkdPIVIucN99",
    "outputId": "9442157c-9639-4906-8f0a-3670192b7988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training score:', 0.13696158649486995)\n",
      "('Validation score:', 0.14582774247790364)\n"
     ]
    }
   ],
   "source": [
    "clf = Ridge(alpha=1.0)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "L415ilvxcN-U"
   },
   "outputs": [],
   "source": [
    "clf = KernelRidge(alpha=0.1)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "IKMhfAhQcN-h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   46.6s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   49.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   45.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   47.5s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   46.7s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training score:', 0.45880050854895255)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation score:', 0.51415876922779058)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingRegressor(n_estimators=300, verbose=1)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "bmSsxPt-cN-o"
   },
   "outputs": [],
   "source": [
    "clf = Lasso(alpha=1e-4)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RyACO3w_cN-0"
   },
   "outputs": [],
   "source": [
    "clf = HuberRegressor()\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "VBk0R4QWcN_I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training score:', -0.38805062644799138)\n",
      "('Validation score:', -0.33710393422641416)\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostRegressor(n_estimators=500)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "DNsDSHFdcN_u"
   },
   "outputs": [],
   "source": [
    "clf = TheilSenRegressor(random_state=45)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "D3Fd7I_AcN__"
   },
   "outputs": [],
   "source": [
    "clf = xg.XGBRegressor(max_depth=5, learning_rate=0.1, n_estimators=300)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "AwoHVuY3cOAL"
   },
   "outputs": [],
   "source": [
    "# clf = svm.SVR()\n",
    "# scores = cv_model(clf)\n",
    "# print ('Training score:', scores.mean())\n",
    "# clf.fit(train_x, train_y)\n",
    "# print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "mpLb68VHcOAx"
   },
   "outputs": [],
   "source": [
    "# clf = svm.SVR(kernel='linear')\n",
    "# scores = cv_model(clf)\n",
    "# print ('Training score:', scores.mean())\n",
    "# clf.fit(train_x, train_y)\n",
    "# print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "H22V3Z_2cOBL"
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5,shuffle=True,random_state=45)\n",
    "\n",
    "parameters = {'max_depth': [3, 5, 10],\n",
    "              'learning_rate' : [0.1, 0.001],\n",
    "              'n_estimators' : [150, 300],\n",
    "              'gamma' : [1, 3],\n",
    "              'reg_lambda': [0.01,]}\n",
    "\n",
    "clf = xg.XGBRegressor()\n",
    "grid_obj = GridSearchCV(clf, parameters, cv=cv, scoring='r2', n_jobs=4, verbose = 5)\n",
    "grid_fit = grid_obj.fit(train_x, train_y)\n",
    "best_clf = grid_fit.best_estimator_ \n",
    "\n",
    "best_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "3LAdhu6gcOBe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 regressors...\n",
      "Fitting regressor1: extratreesregressor (1/1)\n",
      "Fitting 1 regressors...\n",
      "Fitting regressor1: extratreesregressor (1/1)\n",
      "Fitting 1 regressors...\n",
      "Fitting regressor1: extratreesregressor (1/1)\n",
      "Fitting 1 regressors...\n",
      "Fitting regressor1: extratreesregressor (1/1)\n",
      "Fitting 1 regressors...\n",
      "Fitting regressor1: extratreesregressor (1/1)\n",
      "('Stack:', 0.50458041032950152)\n",
      "Fitting 1 regressors...\n",
      "Fitting regressor1: extratreesregressor (1/1)\n",
      "Final r2 score: [0.58195818]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "clf1 = ExtraTreesRegressor(random_state = 45, n_estimators = 300)\n",
    "clf2 = RandomForestRegressor(random_state = 45, n_estimators = 300)\n",
    "clf3 = xg.XGBRegressor(seed = 45, learning_rate = 0.1, n_estimators = 300)\n",
    "clf4 = BaggingRegressor(n_estimators=150)\n",
    "# print ('ExtraTree:', cv_model(clf1))\n",
    "# print ('RF:', cv_model(clf2))\n",
    "# print ('XGB:', cv_model(clf3))\n",
    "# print ('BaggingTree:', cv_model(clf4))\n",
    "# Compute stacking features\n",
    "model =  StackingRegressor(regressors=[clf1], meta_regressor=clf4, verbose=1)\n",
    "print ('Stack:', cv_model(model))\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final r2 score: [%.8f]' % model.score(val_x, val_y))\n",
    "pred_test_y = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uxGTBpcKcOBk"
   },
   "outputs": [],
   "source": [
    "estimators = [('OLS', LinearRegression()),\n",
    "              ('Theil-Sen', TheilSenRegressor(random_state=45)),\n",
    "              ('RANSAC', RANSACRegressor(random_state=45)),\n",
    "              ('HuberRegressor', HuberRegressor())]\n",
    "\n",
    "clf = make_pipeline(RandomForestRegressor(n_estimators=150, max_depth=5), BaggingRegressor())\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))\n",
    "pred_test_y = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "K0S0mKTdcOBv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((11835, 25), (11835,))\n",
      "((3945, 25), (3945,))\n"
     ]
    }
   ],
   "source": [
    "train_X = train_x.as_matrix()\n",
    "train_Y = train_y.as_matrix()\n",
    "val_X = val_x.as_matrix()\n",
    "val_Y = val_y.as_matrix()\n",
    "test_x = test_x.as_matrix()\n",
    "print (train_X.shape, train_Y.shape)\n",
    "print (val_X.shape, val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "CPLj_sOYcOCC"
   },
   "outputs": [],
   "source": [
    "# nn = MLPRegressor(hidden_layer_sizes=(100, ), activation='identity', learning_rate='adaptive', batch_size=16)\n",
    "\n",
    "# nn.fit(train_X, train_Y)\n",
    "# print ('Val r2 score:', nn.score(val_X, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "cxxTa6vmcOCH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11835/11835 [==============================] - 1s - loss: 96.5570 - r2_keras: -1.0895     \n",
      "Epoch 2/100\n",
      "11835/11835 [==============================] - 0s - loss: 91.6544 - r2_keras: -0.9703     \n",
      "Epoch 3/100\n",
      "11835/11835 [==============================] - 0s - loss: 82.4101 - r2_keras: -0.7697     \n",
      "Epoch 4/100\n",
      "11835/11835 [==============================] - 0s - loss: 69.6090 - r2_keras: -0.5411     \n",
      "Epoch 5/100\n",
      "11835/11835 [==============================] - 0s - loss: 56.6724 - r2_keras: -0.3234     \n",
      "Epoch 6/100\n",
      "11835/11835 [==============================] - 0s - loss: 51.2034 - r2_keras: -0.2031     \n",
      "Epoch 7/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.8825 - r2_keras: -0.1527     \n",
      "Epoch 8/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.7735 - r2_keras: -0.1492     \n",
      "Epoch 9/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.7744 - r2_keras: -0.1500     \n",
      "Epoch 10/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.7738 - r2_keras: -0.1488     \n",
      "Epoch 11/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.7735 - r2_keras: -0.1476     \n",
      "Epoch 12/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.7740 - r2_keras: -0.1489     \n",
      "Epoch 13/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.7747 - r2_keras: -0.1483     \n",
      "Epoch 14/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.7744 - r2_keras: -0.1490     \n",
      "Epoch 15/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.7745 - r2_keras: -0.1489     \n",
      "Epoch 16/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.7743 - r2_keras: -0.1476     \n",
      "Epoch 17/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.7749 - r2_keras: -0.1476     \n",
      "Epoch 18/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.7752 - r2_keras: -0.1495     \n",
      "Epoch 19/100\n",
      "11835/11835 [==============================] - 0s - loss: 49.7816 - r2_keras: -0.1476     \n",
      "Epoch 20/100\n",
      " 9152/11835 [======================>.......] - ETA: 0s - loss: 49.8419 - r2_keras: -0.1460"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-07d3875497f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#results = cross_val_score(estimator, train_X, train_Y, cv=kfold, scoring='r2')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#print ('\\nTraining score:', results.mean())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mpred_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Validation score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/wrappers/scikit_learn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m--> 984\u001b[0;31m         self._graph, fetches, feed_dict_string, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \"\"\"\n\u001b[1;32m    336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    265\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 267\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    268\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2581\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2583\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2584\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.metrics import mae\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# custom R2-score metrics for keras backend\n",
    "def r2_keras(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "def base_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim=25, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dense(8, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(3, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=[r2_keras])\n",
    "    \n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=base_model, epochs=100, batch_size=64, verbose=True)\n",
    "#kfold = KFold(n_splits=5, random_state=45)\n",
    "#results = cross_val_score(estimator, train_X, train_Y, cv=kfold, scoring='r2')\n",
    "#print ('\\nTraining score:', results.mean())\n",
    "estimator.fit(train_X, train_Y)\n",
    "pred_Y = estimator.predict(val_X)\n",
    "print ('Validation score:', metrics.r2_score(val_Y, pred_Y))\n",
    "pred_test_y = estimator.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "XXslZdUgcOCQ"
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf\n",
    "\n",
    "train_Y_new = train_Y.reshape(-1,1)\n",
    "val_Y_new = val_Y.reshape(-1,1)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "r2 = tflearn.R2()\n",
    "net = tflearn.input_data(shape=train_X.shape)\n",
    "net = tflearn.fully_connected(net, 25, activation='linear')\n",
    "net = tflearn.fully_connected(net, 10, activation='linear')\n",
    "net = tflearn.fully_connected(net, 1, activation='linear')\n",
    "sgd = tflearn.SGD(learning_rate=0.1, lr_decay=0.01, decay_step=100)\n",
    "net = tflearn.regression(net, optimizer=sgd,loss='mean_absolute', metric=r2)\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "model.fit(train_X, train_Y_new, show_metric=True, validation_set=(val_X, val_Y_new), shuffle=True, n_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "rnIpjzZwcOCY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "YOzUlDTscOCj"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "pJ0NdlNXcOCs"
   },
   "outputs": [],
   "source": [
    "!cat sample_submission.csv | less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "H-dLYe_HcOCy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "pred_test_y = clf.predict(test_x)\n",
    "sub = pd.DataFrame({'Observation':test_data['Observation'], 'Energy':pred_test_y})\n",
    "sub.to_csv('submit.csv', columns=['Observation', 'Energy'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Ki-H7ykFcOC6",
    "outputId": "5ab9b372-db7a-4ca7-defa-2a40e43a2d53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation,Energy\n",
      "50001,43.22\n",
      "50002,89.26\n",
      "50003,54.86\n",
      "50004,70.56\n",
      "50005,49.22\n",
      "50006,72.4\n",
      "50007,147.6\n",
      "50008,44.9\n",
      "50009,308.36\n",
      "50010,43.48\n",
      "50011,48.86\n",
      "50012,74.64\n",
      "50013,48.66\n",
      "50014,98.34\n",
      "50015,59.72\n",
      "50016,109.62\n",
      "50017,57.26\n",
      "50018,464.22\n",
      "50019,64.84\n",
      "50020,90.34\n",
      "50021,70.54\n",
      "50022,107.3\n",
      "\u001b[K50023,113.86\n",
      ":\u001b[K"
     ]
    }
   ],
   "source": [
    "!cat submit.csv | less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "wpcwMotrcODN"
   },
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "vuVPugDqhUhd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Observation', u'Press_mm_hg', u'RH_1', u'RH_2', u'RH_3', u'RH_4',\n",
      "       u'RH_5', u'RH_6', u'RH_7', u'RH_8', u'RH_9', u'RH_out', u'T1', u'T2',\n",
      "       u'T3', u'T4', u'T5', u'T6', u'T7', u'T8', u'T9', u'T_out', u'Tdewpoint',\n",
      "       u'Visibility', u'Windspeed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (big_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1111\n",
       "1        1112\n",
       "2        1113\n",
       "3        1114\n",
       "4        1115\n",
       "5        1116\n",
       "6        1117\n",
       "7        1118\n",
       "8        1119\n",
       "9        1120\n",
       "10       1121\n",
       "11       1122\n",
       "12       1123\n",
       "13       1124\n",
       "14       1125\n",
       "15       1126\n",
       "16       1127\n",
       "17       1128\n",
       "18       1129\n",
       "19       1130\n",
       "20       1131\n",
       "21       1132\n",
       "22       1133\n",
       "23       1134\n",
       "24       1135\n",
       "25       1136\n",
       "26       1137\n",
       "27       1138\n",
       "28       1139\n",
       "29       1140\n",
       "        ...  \n",
       "3915    53916\n",
       "3916    53917\n",
       "3917    53918\n",
       "3918    53919\n",
       "3919    53920\n",
       "3920    53921\n",
       "3921    53922\n",
       "3922    53923\n",
       "3923    53924\n",
       "3924    53925\n",
       "3925    53926\n",
       "3926    53927\n",
       "3927    53928\n",
       "3928    53929\n",
       "3929    53930\n",
       "3930    53931\n",
       "3931    53932\n",
       "3932    53933\n",
       "3933    53934\n",
       "3934    53935\n",
       "3935    53936\n",
       "3936    53937\n",
       "3937    53938\n",
       "3938    53939\n",
       "3939    53940\n",
       "3940    53941\n",
       "3941    53942\n",
       "3942    53943\n",
       "3943    53944\n",
       "3944    53945\n",
       "Name: Observation, Length: 19725, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_data.Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Regression.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
