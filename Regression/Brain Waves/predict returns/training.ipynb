{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge, HuberRegressor, TheilSenRegressor, RANSACRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "import xgboost as xg\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (9366, 18))\n",
      "('Testing set', (4801, 17))\n",
      "  portfolio_id      desk_id    office_id pf_category  start_date         sold  \\\n",
      "0   PF00001002  DSK00001001  OFF00001002           B    20040720  110000000.0   \n",
      "1   PF00001003  DSK00001002  OFF00001001           A    20040709  176671000.0   \n",
      "2   PF00001005  DSK00001004  OFF00001001           A    20040723   56474000.0   \n",
      "3   PF00001006  DSK00001005  OFF00001001           A    20040609  164813000.0   \n",
      "4   PF00001007  DSK00001005  OFF00001002           B    20040609  140800000.0   \n",
      "\n",
      "  country_code  euribor_rate currency  libor_rate        bought  \\\n",
      "0            T       0.02074      USD    2.332216  1.098097e+08   \n",
      "1            N       0.02074      GBP    5.269617  1.760084e+08   \n",
      "2            T       0.02074      USD    2.332216  5.637953e+07   \n",
      "3            T       0.02074      USD    2.332216  1.645088e+08   \n",
      "4            T       0.02074      USD    2.332216  1.405402e+08   \n",
      "\n",
      "   creation_date indicator_code  sell_date type hedge_value status   return  \n",
      "0       20040720            NaN   20040812    B         NaN    NaN  0.02496  \n",
      "1       20040723            NaN   20040812    C         NaN    NaN  0.05496  \n",
      "2       20040723            NaN   20040817    A         NaN    NaN  0.02496  \n",
      "3       20040723            NaN   20040713    A         NaN    NaN  0.02496  \n",
      "4       20040723            NaN   20040713    B         NaN    NaN  0.02496  \n",
      "Index([u'portfolio_id', u'desk_id', u'office_id', u'pf_category',\n",
      "       u'start_date', u'sold', u'country_code', u'euribor_rate', u'currency',\n",
      "       u'libor_rate', u'bought', u'creation_date', u'indicator_code',\n",
      "       u'sell_date', u'type', u'hedge_value', u'status', u'return'],\n",
      "      dtype='object')\n",
      "(bought             True\n",
      "country_code      False\n",
      "creation_date     False\n",
      "currency          False\n",
      "desk_id            True\n",
      "euribor_rate      False\n",
      "hedge_value        True\n",
      "indicator_code     True\n",
      "libor_rate         True\n",
      "office_id         False\n",
      "pf_category       False\n",
      "portfolio_id      False\n",
      "return             True\n",
      "sell_date         False\n",
      "sold               True\n",
      "start_date        False\n",
      "status             True\n",
      "type              False\n",
      "dtype: bool, bought               2\n",
      "country_code         0\n",
      "creation_date        0\n",
      "currency             0\n",
      "desk_id           5613\n",
      "euribor_rate         0\n",
      "hedge_value       8552\n",
      "indicator_code    8550\n",
      "libor_rate         739\n",
      "office_id            0\n",
      "pf_category          0\n",
      "portfolio_id         0\n",
      "return            4801\n",
      "sell_date            0\n",
      "sold                 2\n",
      "start_date           0\n",
      "status            4541\n",
      "type                 0\n",
      "dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "print ('Training set', data.shape)\n",
    "print ('Testing set', test_data.shape)\n",
    "print (data.head(5))\n",
    "print (data.columns)\n",
    "all_data = pd.concat([data, test_data])\n",
    "print (all_data.isnull().any(), all_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought            False\n",
      "country_code      False\n",
      "creation_date     False\n",
      "currency          False\n",
      "desk_id            True\n",
      "euribor_rate      False\n",
      "hedge_value        True\n",
      "indicator_code     True\n",
      "libor_rate        False\n",
      "office_id         False\n",
      "pf_category       False\n",
      "portfolio_id      False\n",
      "return             True\n",
      "sell_date         False\n",
      "sold              False\n",
      "start_date        False\n",
      "status             True\n",
      "type              False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data.dropna(subset = ['sold', 'bought'])\n",
    "all_data['libor_rate'] = all_data['libor_rate'].fillna(all_data['libor_rate'].mean())\n",
    "print (all_data.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((14165, 13), (14165,))\n"
     ]
    }
   ],
   "source": [
    "drop_features = ['desk_id', 'indicator_code', 'return', 'hedge_value', 'status']\n",
    "big_data = all_data.drop(drop_features, axis=1)\n",
    "\n",
    "train_labels = all_data['return']\n",
    "print (big_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bought  country_code  creation_date  currency  euribor_rate  libor_rate  \\\n",
      "0    9126             2              0         4            97         383   \n",
      "1   10999             1              1         2            97         461   \n",
      "2    6411             2              1         4            97         383   \n",
      "3   10712             2              1         4            97         383   \n",
      "4   10285             2              1         4            97         383   \n",
      "\n",
      "   office_id  pf_category  portfolio_id  sell_date  sold  start_date  type  \n",
      "0          1            1             1          7  3868          13     1  \n",
      "1          0            0             2          7  4783           8     2  \n",
      "2          0            0             4         10  2466          14     0  \n",
      "3          0            0             5          1  4664           4     0  \n",
      "4          1            1             6          1  4395           4     1  \n",
      "      bought  country_code  creation_date  currency  euribor_rate  libor_rate  \\\n",
      "0      10929             2              0         4            97         383   \n",
      "1       6412             2              1         4            97         383   \n",
      "2       4633             2              2         4            97         383   \n",
      "3       8079             2              2         4            97         383   \n",
      "4       7486             2              2         4            97         383   \n",
      "5      11336             2              3         4            97         383   \n",
      "6       7465             2              4         4            98         380   \n",
      "7       5076             2              6         4            98         380   \n",
      "8       7893             2              7         4            98         380   \n",
      "9      10990             1              7         2            98         449   \n",
      "10     11382             2              7         4            98         380   \n",
      "11      4537             2              8         4            98         380   \n",
      "12      5657             2             11         4            99         384   \n",
      "13     12128             2             13         4            99         384   \n",
      "14      5042             2             15         4            99         384   \n",
      "15      4497             2             16         4            99         384   \n",
      "16      6408             2             17         4           100         387   \n",
      "17     10992             1             19         2           100         450   \n",
      "18      7532             2             21         4           100         387   \n",
      "19      8997             2             24         4           100         387   \n",
      "20     10940             2             24         4           100         387   \n",
      "21     11956             2             24         4           100         387   \n",
      "22      7845             2             26         4           101         391   \n",
      "23     10839             2             27         4           101         391   \n",
      "24      6856             2             29         4           101         391   \n",
      "25     11002             1             29         2           101         448   \n",
      "26      9954             2             29         4           101         391   \n",
      "27      6711             2             30         4           101         391   \n",
      "28      8816             2             30         4           101         391   \n",
      "29      3570             2             31         4           101         391   \n",
      "...      ...           ...            ...       ...           ...         ...   \n",
      "4771    4006             2           2592         4             1         347   \n",
      "4772    8494             0           2597         0             1          25   \n",
      "4773    3557             0           2629         0             0          21   \n",
      "4774    8015             1           2629         2             0         227   \n",
      "4775    5085             2           2629         4             0         356   \n",
      "4776    6881             2           2641         4             1         343   \n",
      "4777   11877             2           2647         4             1         343   \n",
      "4778    6860             0           2646         0             1          29   \n",
      "4779    4946             0           2646         0             1          29   \n",
      "4780    5678             0           2646         0             1          29   \n",
      "4781    1379             0           2646         0             1          29   \n",
      "4782    4619             2           2647         4             1         343   \n",
      "4783    6126             0           2648         0             1          29   \n",
      "4784    6913             0           2648         0             1          29   \n",
      "4785    1762             2           2649         4             1         343   \n",
      "4786    5097             2           2649         4             1         343   \n",
      "4787    5734             2           2656         4             1         343   \n",
      "4788   11681             0           2745         0            13          31   \n",
      "4789    7987             1           2400         2            12         265   \n",
      "4790    5028             2           2400         4            12         274   \n",
      "4791    7241             0           2400         0            12           6   \n",
      "4792    8985             0           2400         0            12           6   \n",
      "4793    2527             2           2449         4             8         307   \n",
      "4794   10761             0           2513         0             5          30   \n",
      "4795    5073             2           2524         4             4         318   \n",
      "4796    6184             0           2529         0             4          12   \n",
      "4797   10255             0           2529         0             4          12   \n",
      "4798    3298             1           2530         2             4         266   \n",
      "4799    4032             0           2531         0             4          12   \n",
      "4800    5761             0           2534         0             4          12   \n",
      "\n",
      "      office_id  pf_category  portfolio_id  sell_date  sold  start_date  type  \n",
      "0             0            0             0          7  4751          13     0  \n",
      "1             1            1             3          3  2467          14     1  \n",
      "2             0            0             8          0  1886           3     0  \n",
      "3             0            0            12         26  3280          12     0  \n",
      "4             0            0            13          8  3005          11     0  \n",
      "5             0            0            14         22  5020           9     0  \n",
      "6             0            0            16          9  2991          15     0  \n",
      "7             0            0            21          9  1984          10     0  \n",
      "8             0            0            22         33  3205          18     0  \n",
      "9             0            0            23         14  4787          18     2  \n",
      "10            0            0            26         14  5054          18     0  \n",
      "11            0            0            30          8  1830           7     0  \n",
      "12            0            0            34         19  2284          25     0  \n",
      "13            0            0            39         22  5584          27     0  \n",
      "14            1            1            43         24  1983          30     1  \n",
      "15            0            0            45         28  1809          33     0  \n",
      "16            0            0            47         29  2464          35     0  \n",
      "17            0            0            49         32  4789          38     2  \n",
      "18            0            0            55         34  3032          40     0  \n",
      "19            0            0            62         37  3793          43     0  \n",
      "20            0            0            63         24  4762          32     0  \n",
      "21            0            0            64         17  5456          23     0  \n",
      "22            0            0            72         21  3171          27     0  \n",
      "23            0            0            73         39  4682          45     0  \n",
      "24            1            1            80         40  2730          47     1  \n",
      "25            0            0            81         40  4782          47     2  \n",
      "26            0            0            82         41  4213          47     0  \n",
      "27            0            0            83         41  2636          48     0  \n",
      "28            0            0            87         32  3649          48     0  \n",
      "29            1            1            90         43  1508          49     1  \n",
      "...         ...          ...           ...        ...   ...         ...   ...  \n",
      "4771          1            1         12985       2577  1571        2579     1  \n",
      "4772          1            2         13018       2563  3465        2582     4  \n",
      "4773          1            2         13196       2651  1508        2615     4  \n",
      "4774          1            1         13197       2612  3265        2616     2  \n",
      "4775          1            1         13198       2612  1976        2616     1  \n",
      "4776          0            0         13269       2624  2734        2625     0  \n",
      "4777          1            1         13308       2632  5384        2633     1  \n",
      "4778          1            2         13301       2612  2728        2630     4  \n",
      "4779          1            2         13302       2612  1976        2630     4  \n",
      "4780          1            2         13303       2612  2296        2630     4  \n",
      "4781          1            2         13305       2612   561        2630     4  \n",
      "4782          1            1         13307       2653  1874        2633     1  \n",
      "4783          1            2         13320       2614  2397        2632     4  \n",
      "4784          1            2         13323       2610  2755        2632     4  \n",
      "4785          0            0         13325       2673   763        2635     0  \n",
      "4786          1            1         13328       2634  1976        2635     1  \n",
      "4787          0            0         13377       2638  2330        2640     0  \n",
      "4788          1            2         13841       2713  5238        2731     4  \n",
      "4789          1            1         12095       2422  3265        2392     2  \n",
      "4790          1            1         12096       2382  1976        2391     1  \n",
      "4791          1            2         12098       2420  2874        2390     4  \n",
      "4792          1            2         12099       2364  3776        2390     4  \n",
      "4793          1            1         12297       2472  1029        2439     1  \n",
      "4794          1            2         12586       2478  4668        2499     4  \n",
      "4795          1            1         12648       2508  1976        2513     1  \n",
      "4796          1            2         12673       2495  2397        2516     4  \n",
      "4797          1            2         12675       2495  4366        2516     4  \n",
      "4798          1            1         12678       2496  1342        2517     2  \n",
      "4799          1            2         12682       2497  1584        2518     4  \n",
      "4800          1            2         12700       2499  2349        2521     4  \n",
      "\n",
      "[4801 rows x 13 columns]\n",
      "((9364, 13), (9364,), (4801, 13))\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "for c in big_data.columns:\n",
    "    big_data[c] = le.fit_transform(big_data[c])\n",
    "print (big_data.head())\n",
    "\n",
    "train_data = big_data[:9364]\n",
    "train_labels = train_labels[:9364]\n",
    "test_x = big_data[9364:]\n",
    "print (test_x)\n",
    "print (train_data.shape, train_labels.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training shape:', (7023, 13), (7023,))\n",
      "('validation shape:', (2341, 13), (2341,))\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_data, train_labels, test_size=0.25)\n",
    "print ('training shape:', train_x.shape, train_y.shape)\n",
    "print ('validation shape:', val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_model(clf):     \n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=45)\n",
    "    scores = cross_val_score(clf, train_x, train_y, cv=cv, scoring='r2')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(n_estimators=150)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = ExtraTreesRegressor(n_estimators=150, max_depth=5)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = Ridge(alpha=1.0)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = KernelRidge(alpha=0.1)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = BaggingRegressor()\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = Lasso(alpha=1e-4)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = HuberRegressor()\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = AdaBoostRegressor()\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = TheilSenRegressor(random_state=45)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = xg.XGBRegressor(max_depth=5, learning_rate=0.1, n_estimators=150)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clf = svm.SVR()\n",
    "# scores = cv_model(clf)\n",
    "# print ('Training score:', scores.mean())\n",
    "# clf.fit(train_x, train_y)\n",
    "# print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = svm.SVR(kernel='linear')\n",
    "# scores = cv_model(clf)\n",
    "# print ('Training score:', scores.mean())\n",
    "# clf.fit(train_x, train_y)\n",
    "# print ('Validation score:', clf.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5,shuffle=True,random_state=45)\n",
    "\n",
    "parameters = {'max_depth': [3, 5, 10],\n",
    "              'learning_rate' : [0.1, 0.001],\n",
    "              'n_estimators' : [150, 300],\n",
    "              'gamma' : [1, 3],\n",
    "              'reg_lambda': [0.01,]}\n",
    "\n",
    "clf = xg.XGBRegressor()\n",
    "grid_obj = GridSearchCV(clf, parameters, cv=cv, scoring='r2', n_jobs=4, verbose = 5)\n",
    "grid_fit = grid_obj.fit(train_x, train_y)\n",
    "best_clf = grid_fit.best_estimator_ \n",
    "\n",
    "best_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ExtraTree:', 0.83382630289168791)\n",
      "('RF:', 0.81757050850219104)\n",
      "('XGB:', 0.82378593844255921)\n",
      "('BaggingTree:', 0.81307632449198197)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: baggingregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: baggingregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: baggingregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: baggingregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: baggingregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "('Stack:', 0.79187538378318023)\n",
      "Fitting 2 regressors...\n",
      "Fitting regressor1: baggingregressor (1/2)\n",
      "Fitting regressor2: xgbregressor (2/2)\n",
      "Final r2 score: [0.83885254]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "clf1 = ExtraTreesRegressor(random_state = 45, n_estimators = 150, max_depth= 5)\n",
    "clf2 = RandomForestRegressor(random_state = 45, n_estimators = 150)\n",
    "clf3 = xg.XGBRegressor(seed = 45, learning_rate = 0.1, n_estimators = 150, max_depth = 5)\n",
    "clf4 = BaggingRegressor()\n",
    "print ('ExtraTree:', cv_model(clf1))\n",
    "print ('RF:', cv_model(clf2))\n",
    "print ('XGB:', cv_model(clf3))\n",
    "print ('BaggingTree:', cv_model(clf4))\n",
    "# Compute stacking features\n",
    "model =  StackingClassifier(regressors=[clf4, clf3], meta_regressor=clf2, verbose=1)\n",
    "print ('Stack:', cv_model(model))\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final r2 score: [%.8f]' % model.score(val_x, val_y))\n",
    "pred_test_y = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = train_x.as_matrix()\n",
    "train_Y = train_y.as_matrix()\n",
    "val_X = val_x.as_matrix()\n",
    "val_Y = val_y.as_matrix()\n",
    "test_x = test_x.as_matrix()\n",
    "print (train_X.shape, train_Y.shape)\n",
    "print (val_X.shape, val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = MLPRegressor(hidden_layer_sizes=(100, ), activation='identity', learning_rate='adaptive', batch_size=16)\n",
    "\n",
    "nn.fit(train_X, train_Y)\n",
    "print ('Val r2 score:', nn.score(val_X, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.metrics import mae\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# custom R2-score metrics for keras backend\n",
    "def r2_keras(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "def base_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer=Adam(1e-4), metrics=[r2_keras])\n",
    "    \n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=base_model, epochs=100, batch_size=16, verbose=True)\n",
    "#kfold = KFold(n_splits=5, random_state=45)\n",
    "#results = cross_val_score(estimator, train_X, train_Y, cv=kfold, scoring='r2')\n",
    "#print ('\\nTraining score:', results.mean())\n",
    "estimator.fit(train_X, train_Y)\n",
    "pred_Y = estimator.predict(val_X)\n",
    "print ('\\nValidation score:', r2_score(val_Y, pred_Y))\n",
    "pred_test_y = estimator.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf\n",
    "\n",
    "train_Y_new = train_Y.reshape(-1,1)\n",
    "val_Y_new = val_Y.reshape(-1,1)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "r2 = tflearn.R2()\n",
    "net = tflearn.input_data(shape=train_X.shape)\n",
    "net = tflearn.fully_connected(net, 14, activation='linear')\n",
    "net = tflearn.fully_connected(net, 10, activation='linear')\n",
    "net = tflearn.fully_connected(net, 1, activation='linear')\n",
    "sgd = tflearn.SGD(learning_rate=0.1, lr_decay=0.01, decay_step=100)\n",
    "net = tflearn.regression(net, optimizer=sgd,loss='mean_square', metric=r2)\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "model.fit(train_X, train_Y_new, show_metric=True, validation_set=(val_X, val_Y_new), shuffle=True, n_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = xg.XGBRegressor(max_depth=5, learning_rate=0.1, n_estimators=150)\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))\n",
    "pred_test_y = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'portfolio_id':test_data['portfolio_id'], 'return':pred_test_y})\n",
    "sub.to_csv('submit.csv', columns=['portfolio_id', 'return'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training score:', 0.78423188615206296)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation score:', 0.9404296210349441)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "estimators = [('OLS', LinearRegression()),\n",
    "              ('Theil-Sen', TheilSenRegressor(random_state=45)),\n",
    "              ('RANSAC', RANSACRegressor(random_state=45)),\n",
    "              ('HuberRegressor', HuberRegressor())]\n",
    "\n",
    "clf = make_pipeline(RandomForestRegressor(n_estimators=150, max_depth=5), BaggingRegressor())\n",
    "scores = cv_model(clf)\n",
    "print ('Training score:', scores.mean())\n",
    "clf.fit(train_x, train_y)\n",
    "print ('Validation score:', clf.score(val_x, val_y))\n",
    "pred_test_y = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
