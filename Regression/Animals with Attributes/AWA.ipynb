{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from IPython.display import display\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import BatchNormalization, GlobalAveragePooling2D, Dense, Activation, Dropout\n",
    "from keras.layers import MaxPooling2D, Conv2D, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import regularizers\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "print(os.listdir(\"../input/dl3-dataset/meta-data/meta-data/\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "1. Load the given training data [Images, Attributes]\n",
    "2. Preprocess the images [resize, rescale]\n",
    "3. Use Transfer Learning with VGG19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/dl3-dataset/meta-data/meta-data/train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "266c451c-ad61-451f-a2d8-4d3bf0892523",
    "_uuid": "4006b9052d0bf4c174194364dc1088b1f48b6c17",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = pd.read_csv('../input/dl3-dataset/classes.txt', header=None)\n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "7e0ba32c-4fd4-4c90-8d71-9a10e15ff73e",
    "_uuid": "46b8cf2b3659b50a0a11348fd287e9fbd0117dcb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "att = pd.read_csv('../input/dl3-dataset/attributes.txt', header=None)\n",
    "att.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "1b3f0b05-1b9f-4b66-8b85-ef71317cbc90",
    "_uuid": "eb6d8d0098498202f1f04a201533c76a202a69f0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_cols = list(set(train_data.columns) - set(['Image_name']))\n",
    "label_cols.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "d9260f98-3ffb-421f-81d6-4fdc10a29e81",
    "_uuid": "b2d8ae13b181a56961d977f189bf4035033ecf4e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = random.randint(1, len(train_data))\n",
    "im = Image.open(os.path.join('../input/dl3-dataset/train_img/train_img', train_data.Image_name[i]))\n",
    "labels = train_data.iloc[i][2:].index[train_data.iloc[i][2:] == 1]\n",
    "plt.imshow(im)\n",
    "print (im.size)\n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b6fd1acd-7524-4e89-b396-3ebce84d1149",
    "_uuid": "7e33869d14fa4a14f84b62660cfa3d786eca2376",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def prep_data(x):\n",
    "#     d = []\n",
    "#     for i in x:\n",
    "#         img = cv2.imread(os.path.join('../input/dl3-dataset/train_img/train_img', i))\n",
    "#         img = cv2.resize(img, (128, 128))\n",
    "#         img = img / 255.\n",
    "#         d.append(img)\n",
    "#     return np.array(d, np.float32)\n",
    "\n",
    "def prep_data(x_d):\n",
    "    d = []\n",
    "    for i in tqdm(x_d):\n",
    "        img = image.load_img(os.path.join('../input/dl3-dataset/train_img/train_img', i), target_size=(128, 128))\n",
    "        x = image.img_to_array(img)\n",
    "        x = x / 255.\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = np.squeeze(preprocess_input(x))\n",
    "        d.append(x)\n",
    "    return np.array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "ddfaf99e-5f70-41eb-9ad9-764006378a4f",
    "_uuid": "9ddb2860f5826cb5a201da31e5f74e5a3a14439b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = prep_data(train_data.Image_name.values)\n",
    "display(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "1f404470-7a1d-4e23-a9f6-1bb42c809677",
    "_uuid": "2f24a8dfe0d3d0406625b0a60872b3c6c93c4313",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = train_data.drop(['Image_name'], axis=1)\n",
    "display(labels.head())\n",
    "labels = np.array(labels)\n",
    "display(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "c3c32645-8847-4d9b-b222-2ce0da88551a",
    "_uuid": "328b8b5583e6374257338eb4f411c2ce263d4d5f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x,val_x, train_y, val_y = train_test_split(data, labels, test_size=0.2, shuffle=True)\n",
    "print ('Training shape', train_x.shape, train_y.shape)\n",
    "print ('Validation shape', val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "3ff91038-722e-419f-a515-be3c8bc35ca3",
    "_uuid": "e0c8e6530f24f1043a97029e06b2b4fe07aa8699",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_data, data, labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "4a53f29c-1823-4781-aaf5-18dda0d097a2",
    "_uuid": "2d45c5fde846f8c292b01786154a070b2dcfdf07",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 25\n",
    "num_classes = len(att)\n",
    "iters_train = train_x.shape[0] / batch_size\n",
    "iters_val = val_x.shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "21f3fc0a4368700e38f511a6cd836791a20d426a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2,\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True, rotation_range = 20)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "b31f66c98e3985c61c2377965a1f1284aacd3212",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen.fit(train_x)\n",
    "val_datagen.fit(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aae4f023-4d07-4897-b2c4-23b1a75889d9",
    "_uuid": "845ea8e86abdb2387a6b9164f2bf42535e6def14",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only needed for Kaggle Kernel, locally just use weights='imagenet'\n",
    "vgg19_fl = \"../input/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "base_model = VGG19(weights=vgg19_fl, include_top=False, input_shape=(128, 128, 3))\n",
    "# Freeze the layers in base model\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    layer.trainable = False\n",
    "    \n",
    "x_i = base_model.output\n",
    "x_i = GlobalAveragePooling2D()(x_i)\n",
    "x_i = Dense(200)(x_i)\n",
    "x_i = BatchNormalization()(x_i)\n",
    "x_i = Activation('relu')(x_i)\n",
    "x_i = Dropout(0.5)(x_i)\n",
    "# x_i = Dense(512)(x_i)\n",
    "# x_i = BatchNormalization()(x_i)\n",
    "# x_i = Activation('relu')(x_i)\n",
    "# x_i = Dropout(0.5)(x_i)\n",
    "predictions = Dense(num_classes, activation='sigmoid')(x_i)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()\n",
    "opt = Adam(lr=1e-3, decay=1e-6)\n",
    "filepath = 'model_vgg19.hdf5'\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['acc'])\n",
    "mc = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "# history = model.fit(train_x, train_y, validation_data=(val_x, val_y), batch_size=batch_size, epochs=4, verbose=1)\n",
    "model.fit_generator(train_datagen.flow(train_x, train_y, batch_size=batch_size),                     \n",
    "                    steps_per_epoch=iters_train, epochs=5,\n",
    "                    validation_data=val_datagen.flow(val_x, val_y, batch_size=batch_size), \n",
    "                    validation_steps = iters_val, callbacks=[early_stopping, mc], workers = 10, max_queue_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "34e50ae7-6a9b-4a0f-b3cf-247cb0a2128c",
    "_uuid": "bfcb55f1eb68bf59c96b24d14de3cbe13ad7d18c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers[:17]):\n",
    "    layer.trainable = False\n",
    "\n",
    "for i, layer in enumerate(model.layers[17:]):\n",
    "    layer.trainable = True\n",
    "\n",
    "opt = SGD(lr=0.001, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "filepath = 'model_vgg19_finetune.hdf5'\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['acc'])\n",
    "mc = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "# history = model.fit(train_x, train_y, validation_data=(val_x, val_y), batch_size=batch_size, epochs=num_epochs, callbacks=[early_stopping, mc], verbose=1)\n",
    "# model.fit_generator(train_generator(), steps_per_epoch=iters_train, epochs=num_epochs, \n",
    "#                     verbose=1, validation_data=valid_generator(), validation_steps=iters_val)\n",
    "model.fit_generator(train_datagen.flow(train_x, train_y, batch_size=batch_size),                     \n",
    "                    steps_per_epoch=iters_train, epochs=5,\n",
    "                    validation_data=val_datagen.flow(val_x, val_y, batch_size=batch_size), \n",
    "                    validation_steps = iters_val, callbacks=[early_stopping, mc], workers = 10, max_queue_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "35c73b58-5b27-4be9-9cbd-dfd88ea62f39",
    "_uuid": "da13e130cce7dd14163bd1c39b51587fcc5c135c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(128, 128, 3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(Conv2D(50, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(50, kernel_size=(3, 3), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(100, kernel_size=(3, 3), padding='same', kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(100, kernel_size=(3, 3), kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(85, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()\n",
    "opt = Adam(lr=1e-3, decay=1e-6)\n",
    "filepath = 'model_custom.hdf5'\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['acc'])\n",
    "mc = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "# history = model.fit(train_x, train_y, validation_data=(val_x, val_y), batch_size=batch_size, epochs=num_epochs, verbose=1)\n",
    "# model.fit_generator(train_generator(), steps_per_epoch=iters_train, epochs=num_epochs, \n",
    "#                     verbose=1, validation_data=valid_generator(), validation_steps=iters_val)\n",
    "model.fit_generator(train_datagen.flow(train_x, train_y, batch_size=batch_size),                     \n",
    "                    steps_per_epoch=iters_train, epochs=25,\n",
    "                    validation_data=val_datagen.flow(val_x, val_y, batch_size=batch_size), \n",
    "                    validation_steps = iters_val, callbacks=[early_stopping, mc], workers = 10, max_queue_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "c5ee4d01-9731-42b4-9d9b-27f12c5af4ba",
    "_uuid": "280d23d8ab255d5ff713fd2a4e083b7fe81dc470",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "80350e0f-9849-4881-8144-a6d895e40329",
    "_uuid": "ee82576dfd783bf75cb446ffcf2b701abc96839f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "val_pred = model.predict(val_x).round()\n",
    "print ('Time for prediction', time.time()-start)\n",
    "print (val_pred[0], val_pred[0].shape)\n",
    "print (val_y[0], val_y[0].shape)\n",
    "print (f1_score(val_y, val_pred, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "be086660-67e2-410f-ac9b-643696a98e07",
    "_uuid": "43048367077dfbc8f69fe585d280dad8521b3f56",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "579cd6c8-5bd2-4aae-bd53-e19c1decc0bf",
    "_uuid": "1421fd1ed5f230d506e9044a0fa0b2a62d151883",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../input/meta-data/meta-data/test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8e50720b-2144-4b8d-b8ed-9d8350bf2e4f",
    "_uuid": "7bdccd275ae93a8943099e8ebdc54e482ee5aa15",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = prep_data(test_data)\n",
    "sub = pd.DataFrame(columns=[''])\n",
    "sub['Image_name'] = test_data.Image_name\n",
    "del test_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "47b4f33b-2b2c-490a-9bb8-b2e75c789ee2",
    "_uuid": "8ad85ae211eebdeb8d4499a1bbedbce1a0d13832",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "test_pred = model.predict(test_x).round()\n",
    "print ('Time for prediction', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2be1dd53-9cbd-456e-a3df-9917b35ed3f2",
    "_uuid": "0c1738cfaafc09619fb3645adfd05e2dfeacc5df",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_df = pd.DataFrame(data=test_pred, columns=label_cols)\n",
    "sub = pd.concat([sub, label_df], axis=1)\n",
    "sub.to_csv('submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
