{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from timeit import time\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg19 import VGG19\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Activation, GlobalAveragePooling2D, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "1. Load training and testing data                                    [Loading Stage]\n",
    "2. Perform all sorts of analysis on data and prepare it for training [Preprocessing Stage]\n",
    "3. Throw all sorts of model (Transfer Learning, Fine Tuning)         [Training Stage]\n",
    "4. Validate the results of the model                                 [Nothing Ok! Stage]\n",
    "5. Return to Step 3 if not okay else submit                          [Everything Ok! Stage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '../input/cavvo-deep-learning/train/train/'\n",
    "test_dir = '../input/cavvo-deep-learning/test/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5c6fad58-ddd8-4541-b1fc-1d8446293198",
    "_uuid": "2a90247fb9fd59b36cc3a8a3ece42e5ce28657ee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "def read_img_labels(image_dir):\n",
    "    for root, directories, files in os.walk(image_dir):\n",
    "        for d in directories:\n",
    "            for filename in tqdm(os.listdir(os.path.join(image_dir, d))):\n",
    "                data.append([os.path.join(image_dir, d ,filename), d])\n",
    "%time read_img_labels(train_dir)\n",
    "train_data = pd.DataFrame(data, columns=['imgs', 'labels'])\n",
    "print (train_data.shape)\n",
    "print (train_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d0b46d7a-fbe7-41a8-ae4a-11ddff3a5a14",
    "_uuid": "738727bbdfe16db352a2e68216c5bbc8fa678a8e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(y='labels', data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85b1feb9-7db3-4618-bb1c-5348f39e5643",
    "_uuid": "56f3898739d1932ecb2cc1c08a5ad8e15f3cade6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = train_data['imgs'], train_data['labels']\n",
    "print (x[0], y[0])\n",
    "print (x.shape, y.shape)\n",
    "lb = LabelEncoder()\n",
    "y = lb.fit_transform(y)\n",
    "y = to_categorical(y, num_classes=len(train_data['labels'].unique()))\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2bf4cd9-4baf-40a5-ab18-f0bcb9381e1f",
    "_uuid": "81b04d6fc4057447884d00fbcc9fd455bd5e64b3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_imgs(img_path):\n",
    "    data = []\n",
    "    for imgs in img_path:\n",
    "            img = image.load_img(imgs, target_size=(224, 224))\n",
    "            x_im = image.img_to_array(img)\n",
    "            x_im = np.expand_dims(x_im, axis=0)\n",
    "            x_im = preprocess_input(x_im)\n",
    "            data.append(x_im)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ca4e7f69-7434-468b-af81-a5121c69c61c",
    "_uuid": "cd6cc6c41dba0c20faf4f466a12712d31ccb4a65",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(x, y, shuffle=True, stratify=y, test_size=0.20)\n",
    "print ('Training', train_x.shape, train_y.shape)\n",
    "print ('Validation', val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "642a909f-46ab-41c3-9cbd-2cdd27b556fe",
    "_uuid": "6b5105d998d7f952f21b47f0a0413c6f4fecd7a6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ints = [y.argmax() for y in train_y]\n",
    "print (len(y_ints))\n",
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(y_ints), y_ints)\n",
    "class_weight_dict = dict(enumerate(class_weight))\n",
    "print (class_weight)\n",
    "print (class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1b102262-91a7-43a2-8f98-6f9f3e412a6c",
    "_uuid": "b607ce6caf80b3528e7a50330389ad10dc4e04ab",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "num_classes = len(train_data['labels'].unique())\n",
    "iters_train = train_x.shape[0] / batch_size\n",
    "iters_val = val_x.shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "72f7bd2f-c0aa-448a-bd81-9b86f14156f0",
    "_uuid": "a3b3d694420589f338e5b06904927151eb44c4ad",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    num_iters = train_x.shape[0] / batch_size\n",
    "    while True:\n",
    "        for i in range(int(num_iters)):\n",
    "            temp_X = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            temp_Y = train_y[i*batch_size:(i+1)*batch_size]\n",
    "            train_data = preprocess_imgs(temp_X)\n",
    "            train_labels = temp_Y\n",
    "            train_data = np.array(np.squeeze(train_data))\n",
    "            train_labels = np.array(train_labels)\n",
    "            yield train_data, train_labels\n",
    "\n",
    "def valid_generator():\n",
    "    num_iters = val_x.shape[0] / batch_size\n",
    "    while True:\n",
    "        for i in range(int(num_iters)):\n",
    "            temp_X = val_x[i*batch_size:(i+1)*batch_size]\n",
    "            temp_Y = val_y[i*batch_size:(i+1)*batch_size]\n",
    "            val_data = preprocess_imgs(temp_X)\n",
    "            val_labels = temp_Y\n",
    "            val_data = np.array(np.squeeze(val_data))\n",
    "            val_labels = np.array(val_labels)\n",
    "            yield val_data, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b8f86d2b-e54a-4c38-81d8-fddb156a2a87",
    "_uuid": "8af9278b00b578ee7674e8db37df6590ece2f6af",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only needed for Kaggle Kernel, locally just use weights='imagenet'\n",
    "vgg19_fl = \"../input/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "base_model = VGG19(weights=vgg19_fl, include_top=False, input_shape=(224, 224, 3))\n",
    "# Freeze the layers in base model\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    layer.trainable = False\n",
    "#     print (i, layer.name)\n",
    "x_i = base_model.output\n",
    "x_i = GlobalAveragePooling2D()(x_i)\n",
    "x_i = Dense(1024)(x_i)\n",
    "x_i = BatchNormalization()(x_i)\n",
    "x_i = Activation('relu')(x_i)\n",
    "x_i = Dropout(0.5)(x_i)\n",
    "x_i = Dense(512)(x_i)\n",
    "x_i = BatchNormalization()(x_i)\n",
    "x_i = Activation('relu')(x_i)\n",
    "x_i = Dropout(0.5)(x_i)\n",
    "predictions = Dense(num_classes, activation='softmax')(x_i)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# model.summary()\n",
    "opt = Adam(lr=1e-3, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.fit_generator(train_generator(), steps_per_epoch=iters_train, epochs=num_epochs, \n",
    "                    verbose=1, validation_data=valid_generator(), validation_steps=iters_val,\n",
    "                   class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1874ab16-b368-4771-af42-f38653507713",
    "_uuid": "498e2ac1cd751c16424c32c5f22df4f662d2604c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator(), steps_per_epoch=iters_train, epochs=1, \n",
    "                    verbose=1, validation_data=valid_generator(), validation_steps=iters_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8e273c92-ba21-4f3b-a93d-cc8c11161699",
    "_uuid": "7da6c70022ccacbc3ecdbe3ef2cd36248eec6751",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator(), steps_per_epoch=iters_train, epochs=2, \n",
    "                    verbose=1, validation_data=valid_generator(), validation_steps=iters_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7720bdea-51df-4ce6-b131-fdade09f7307",
    "_uuid": "8892b3476e9302f388f98455bb6a486b4771b792",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator(), steps_per_epoch=iters_train, epochs=2, \n",
    "                    verbose=1, validation_data=valid_generator(), validation_steps=iters_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f5c98ea-14c9-483e-ad9e-1e8bca5ec07e",
    "_uuid": "83dd2223327547ebc0b33907b7218acd60ac4688",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator(), steps_per_epoch=iters_train, epochs=1, \n",
    "                    verbose=1, validation_data=valid_generator(), validation_steps=iters_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "26bc702f-576e-4e7a-96e8-5ba581139b40",
    "_uuid": "d6db02940a15dcc03f96edbba295036d89cb8943",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator(), steps_per_epoch=iters_train, epochs=1, \n",
    "                    verbose=1, validation_data=valid_generator(), validation_steps=iters_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c057e5c2-3e3b-4e7f-bb9a-5b5bde6a8c6d",
    "_uuid": "1efd5cd079c0d105d10b44db1e54270c925aab55",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator(), steps_per_epoch=iters_train, epochs=2, \n",
    "                    verbose=1, validation_data=valid_generator(), validation_steps=iters_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e65f3b97-6c9f-4ad5-abf2-c0aa8c8e20dc",
    "_uuid": "a394f5ff877788324fdcc950e0f0c2dac70ca9bc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator(), steps_per_epoch=iters_train, epochs=2, \n",
    "                    verbose=1, validation_data=valid_generator(), validation_steps=iters_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "be292029-8ffe-4fad-86b1-1612d13cfce1",
    "_uuid": "5df3b987f79d2228dab455a9f6ed50140510c18c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator(), steps_per_epoch=iters_train, epochs=1, \n",
    "                    verbose=1, validation_data=valid_generator(), validation_steps=iters_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4070372b-921d-438b-a97f-36aa93e69aed",
    "_uuid": "236cb5d91a380611c1e8ffe89f3537f300bc1a37",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('vgg19_model_batchnorm_activation_class_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "40e8f47f-2092-430d-a8c0-9b078b18aea1",
    "_uuid": "9cd5844b14bd3b17173f4d68c0602b50c0aeec8c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "def read_img_labels(image_dir):\n",
    "    for root, directory, files in os.walk(image_dir):\n",
    "            for filename in tqdm(files):\n",
    "                test_ex =  os.path.join(image_dir, filename)\n",
    "                img = image.load_img(test_ex, target_size=(224, 224))\n",
    "                x_im = image.img_to_array(img)\n",
    "                x_im = np.expand_dims(x_im, axis=0)\n",
    "                x_im = preprocess_input(x_im)\n",
    "                prediction = model.predict(x_im)\n",
    "\n",
    "                data.append([filename, np.argmax(prediction)])\n",
    "                \n",
    "%time read_img_labels(test_dir)\n",
    "test_data = pd.DataFrame(data, columns=['image_name', 'category'])\n",
    "print (test_data.shape)\n",
    "print (test_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "42d0bb9c-4860-432e-adae-ee30b3a8c080",
    "_uuid": "4ac42ad2bc93267ae05c822be81044a80c76c597",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.to_csv('submit_vgg19_model_batchnorm_activation_class_weight.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
